{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using HyperDrive\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1668559188667
    }
   },
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice, uniform\n",
    "from azureml.core import Environment, ScriptRunConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1668559190442
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# choose a name for experiment\n",
    "experiment_name = 'nba_hyperdrive'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1668559205024
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Read Data\n",
    "dataset = Dataset.get_by_name(ws, name='nba-games-data')\n",
    "df = dataset.to_pandas_dataframe()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(df, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1668559241991
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "x_train = train_data.iloc[:,:-1]\n",
    "y_train = train_data['HOME_TEAM_WINS']\n",
    "x_test = test_data.iloc[:,:-1]\n",
    "y_test = test_data['HOME_TEAM_WINS']\n",
    "x_train = x_train.fillna(0)\n",
    "x_test = x_test.fillna(0)\n",
    "\n",
    "x_train.to_csv('./data/x_train.csv', index=False)\n",
    "y_train.to_csv('./data/y_train.csv', index=False)\n",
    "x_test.to_csv('./data/x_test.csv', index=False)\n",
    "y_test.to_csv('./data/y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598531923519
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Hyperdrive Configuration\n",
    "\n",
    "TODO: Explain the model you are using and the reason for chosing the different hyperparameters, termination policy and config settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1668559253021
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress..\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "\n",
    "compute_name = 'nba-compute'\n",
    "compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS2_V2', max_nodes=5)\n",
    "train_cluster = ComputeTarget.create(ws, compute_name, compute_config)\n",
    "train_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1668559253262
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Create an early termination policy. This is not required if you are using Bayesian sampling.\n",
    "early_termination_policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n",
    "\n",
    "#TODO: Create the different params that you will be using during training\n",
    "param_sampling = RandomParameterSampling(\n",
    "    {\n",
    "        '--C': choice(0.01, 0.1, 1),\n",
    "        '--max_iter': choice(10, 20, 50, 100, 250)\n",
    "    }\n",
    ")\n",
    "\n",
    "#TODO: Create your estimator and hyperdrive config\n",
    "sklearn_env = Environment.from_conda_specification(\n",
    "    name='sklearn_env',\n",
    "    file_path='conda_dependencies.yml'\n",
    ")\n",
    "\n",
    "estimator = ScriptRunConfig(\n",
    "    source_directory='.',\n",
    "    script='train.py',\n",
    "    arguments=['--data_directory', './data'],\n",
    "    environment=sklearn_env,\n",
    "    compute_target=train_cluster\n",
    ")\n",
    "\n",
    "hyperdrive_run_config = HyperDriveConfig(\n",
    "    run_config=estimator,\n",
    "    policy=early_termination_policy,\n",
    "    hyperparameter_sampling=param_sampling,\n",
    "    primary_metric_name='AUC_weighted',\n",
    "    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "    max_total_runs=5,\n",
    "    max_concurrent_runs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "gather": {
     "logged": 1668564489191
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Submit your experiment\n",
    "hyperdrive_run = experiment.submit(config=hyperdrive_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598544898497
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "gather": {
     "logged": 1668564489556
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de437c80bd9343f8bc4f0e40a65a8f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/HD_46fed949-e65d-474a-95d6-1c8c311ca74c?wsid=/subscriptions/3e42d11f-d64d-4173-af9b-12ecaa1030b3/resourcegroups/aml-quickstarts-215640/workspaces/quick-starts-ws-215640&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\", \"run_id\": \"HD_46fed949-e65d-474a-95d6-1c8c311ca74c\", \"run_properties\": {\"run_id\": \"HD_46fed949-e65d-474a-95d6-1c8c311ca74c\", \"created_utc\": \"2022-11-16T02:08:08.840878Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\":\\\"AUC_weighted\\\",\\\"goal\\\":\\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"ef8ee8bf-5846-4567-91ea-3153225be85f\", \"user_agent\": \"python/3.8.5 (Linux-5.15.0-1017-azure-x86_64-with-glibc2.10) msrest/0.7.1 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.44.0\", \"space_size\": \"15\", \"score\": \"0.9229796410486066\", \"best_child_run_id\": \"HD_46fed949-e65d-474a-95d6-1c8c311ca74c_1\", \"best_metric_status\": \"Succeeded\", \"best_data_container_id\": \"dcid.HD_46fed949-e65d-474a-95d6-1c8c311ca74c_1\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"5\", \"_aml_system_max_total_jobs\": \"5\", \"_aml_system_max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\":\\\"Bandit\\\",\\\"properties\\\":{\\\"evaluation_interval\\\":2,\\\"delay_evaluation\\\":0,\\\"slack_factor\\\":0.1}}\", \"_aml_system_generator_config\": \"{\\\"name\\\":\\\"RANDOM\\\",\\\"parameter_space\\\":{\\\"--C\\\":[\\\"choice\\\",[[0.01,0.1,1]]],\\\"--max_iter\\\":[\\\"choice\\\",[[10,20,50,100,250]]]},\\\"properties\\\":null}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\":\\\"AUC_weighted\\\",\\\"goal\\\":\\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"SubscriptionId\\\": \\\"3e42d11f-d64d-4173-af9b-12ecaa1030b3\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-215640\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-215640\\\", \\\"ExperimentName\\\": \\\"nba_hyperdrive\\\", \\\"Definition\\\": {\\\"Configuration\\\": null, \\\"Attribution\\\": null, \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"436b5885-ee5c-4e7b-84df-748c2dade737\\\", \\\"amlClientSessionId\\\": \\\"dbb85df2-8e2d-4e3e-b514-8b4312069168\\\", \\\"subscriptionId\\\": \\\"3e42d11f-d64d-4173-af9b-12ecaa1030b3\\\", \\\"estimator\\\": \\\"NoneType\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 5, \\\"maxConcurrentRuns\\\": 5, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}, \\\"Overrides\\\": {\\\"Script\\\": \\\"train.py\\\", \\\"Command\\\": \\\"\\\", \\\"UseAbsolutePath\\\": false, \\\"Arguments\\\": [\\\"--data_directory\\\", \\\"./data\\\"], \\\"SourceDirectoryDataStore\\\": null, \\\"Framework\\\": 0, \\\"Communicator\\\": 0, \\\"Target\\\": \\\"nba-compute\\\", \\\"DataReferences\\\": {}, \\\"Data\\\": {}, \\\"OutputData\\\": {}, \\\"Datacaches\\\": [], \\\"JobName\\\": null, \\\"MaxRunDurationSeconds\\\": 2592000, \\\"NodeCount\\\": 1, \\\"InstanceTypes\\\": [], \\\"Priority\\\": null, \\\"CredentialPassthrough\\\": false, \\\"Identity\\\": null, \\\"Environment\\\": {\\\"Name\\\": \\\"sklearn_env\\\", \\\"AutoRebuild\\\": true, \\\"Python\\\": {\\\"InterpreterPath\\\": \\\"python\\\", \\\"UserManagedDependencies\\\": false, \\\"CondaDependencies\\\": {\\\"dependencies\\\": [\\\"python=3.6.2\\\", \\\"scikit-learn\\\", \\\"numpy\\\", \\\"pandas\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\"]}]}, \\\"BaseCondaEnvironment\\\": null}, \\\"EnvironmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"Docker\\\": {\\\"BaseImage\\\": \\\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1\\\", \\\"Platform\\\": {\\\"Os\\\": \\\"Linux\\\", \\\"Architecture\\\": \\\"amd64\\\"}, \\\"BaseDockerfile\\\": null, \\\"BaseImageRegistry\\\": {\\\"Address\\\": null, \\\"Username\\\": null, \\\"Password\\\": null}, \\\"Enabled\\\": false, \\\"Arguments\\\": []}, \\\"Spark\\\": {\\\"Repositories\\\": [], \\\"Packages\\\": [], \\\"PrecachePackages\\\": true}, \\\"InferencingStackVersion\\\": null}, \\\"History\\\": {\\\"OutputCollection\\\": true, \\\"DirectoriesToWatch\\\": [\\\"logs\\\"], \\\"EnableMLflowTracking\\\": true, \\\"snapshotProject\\\": true}, \\\"Spark\\\": {\\\"Configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": \\\"1\\\"}}, \\\"ParallelTask\\\": {\\\"MaxRetriesPerWorker\\\": 0, \\\"WorkerCountPerNode\\\": 1, \\\"TerminalExitCodes\\\": null, \\\"Configuration\\\": {}}, \\\"BatchAi\\\": {\\\"NodeCount\\\": 0}, \\\"AmlCompute\\\": {\\\"Name\\\": null, \\\"VmSize\\\": null, \\\"RetainCluster\\\": false, \\\"ClusterMaxNodeCount\\\": null}, \\\"AISuperComputer\\\": {\\\"InstanceType\\\": \\\"D2\\\", \\\"FrameworkImage\\\": null, \\\"ImageVersion\\\": \\\"pytorch-1.7.0\\\", \\\"Location\\\": null, \\\"AISuperComputerStorageData\\\": null, \\\"Interactive\\\": false, \\\"ScalePolicy\\\": null, \\\"VirtualClusterArmId\\\": null, \\\"TensorboardLogDirectory\\\": null, \\\"SSHPublicKey\\\": null, \\\"SSHPublicKeys\\\": null, \\\"EnableAzmlInt\\\": true, \\\"Priority\\\": \\\"Medium\\\", \\\"SLATier\\\": \\\"Standard\\\", \\\"UserAlias\\\": null}, \\\"KubernetesCompute\\\": {\\\"InstanceType\\\": null}, \\\"Tensorflow\\\": {\\\"WorkerCount\\\": 1, \\\"ParameterServerCount\\\": 1}, \\\"Mpi\\\": {\\\"ProcessCountPerNode\\\": 1}, \\\"PyTorch\\\": {\\\"CommunicationBackend\\\": \\\"nccl\\\", \\\"ProcessCount\\\": null}, \\\"Hdi\\\": {\\\"YarnDeployMode\\\": 2}, \\\"ContainerInstance\\\": {\\\"Region\\\": null, \\\"CpuCores\\\": 2.0, \\\"MemoryGb\\\": 3.5}, \\\"ExposedPorts\\\": null, \\\"Docker\\\": {\\\"UseDocker\\\": false, \\\"SharedVolumes\\\": true, \\\"ShmSize\\\": \\\"2g\\\", \\\"Arguments\\\": []}, \\\"Cmk8sCompute\\\": {\\\"Configuration\\\": {}}, \\\"CommandReturnCodeConfig\\\": {\\\"ReturnCode\\\": 0, \\\"SuccessfulReturnCodes\\\": []}, \\\"EnvironmentVariables\\\": {}, \\\"ApplicationEndpoints\\\": {}, \\\"Parameters\\\": []}, \\\"SnapshotId\\\": \\\"ef8ee8bf-5846-4567-91ea-3153225be85f\\\", \\\"Snapshots\\\": [], \\\"SourceCodeDataReference\\\": null, \\\"ParentRunId\\\": null, \\\"DataContainerId\\\": null, \\\"RunType\\\": null, \\\"DisplayName\\\": null, \\\"EnvironmentAssetId\\\": null, \\\"Properties\\\": {}, \\\"Tags\\\": {}, \\\"AggregatedArtifactPath\\\": null}, \\\"ParentRunId\\\": \\\"HD_46fed949-e65d-474a-95d6-1c8c311ca74c\\\"}\", \"_aml_system_resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"true\", \"_aml_system_cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2022-11-16T02:08:09.892859\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"93b60ee540bad60dfb9a21954b9993ff12e1123eff00beddd1aa258e7b61e707\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2022-11-16T02:08:09.892859\\\"\", \"_aml_system_optimizer_state_artifact\": \"null\", \"_aml_system_outdated_optimizer_state_artifacts\": \"\\\"[]\\\"\", \"_aml_system_HD_46fed949-e65d-474a-95d6-1c8c311ca74c_0\": \"{\\\"--C\\\": 0.1, \\\"--max_iter\\\": 20}\", \"_aml_system_HD_46fed949-e65d-474a-95d6-1c8c311ca74c_1\": \"{\\\"--C\\\": 0.1, \\\"--max_iter\\\": 100}\", \"_aml_system_HD_46fed949-e65d-474a-95d6-1c8c311ca74c_2\": \"{\\\"--C\\\": 0.1, \\\"--max_iter\\\": 50}\", \"_aml_system_HD_46fed949-e65d-474a-95d6-1c8c311ca74c_3\": \"{\\\"--C\\\": 0.01, \\\"--max_iter\\\": 10}\", \"_aml_system_HD_46fed949-e65d-474a-95d6-1c8c311ca74c_4\": \"{\\\"--C\\\": 0.1, \\\"--max_iter\\\": 10}\", \"_aml_system_final_best_metric_update_retry_count\": \"1\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2022-11-16T02:10:42.115759Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://mlstrg215640.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_46fed949-e65d-474a-95d6-1c8c311ca74c/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=RErlunP2%2FEozSw3IN6gw26pKCuxMYVhJDSvwk5uThKU%3D&skoid=843a364e-dd11-4f0c-b65f-a5c5aca461d0&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2022-11-16T00%3A30%3A58Z&ske=2022-11-17T08%3A40%3A58Z&sks=b&skv=2019-07-07&st=2022-11-16T03%3A36%3A56Z&se=2022-11-16T11%3A46%3A56Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:02:33\", \"run_number\": \"1668564488\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}, \"hyper_parameters\": {\"--C\": [\"choice\", [[0.01, 0.1, 1]]], \"--max_iter\": [\"choice\", [[10, 20, 50, 100, 250]]]}}, \"child_runs\": [{\"run_id\": \"HD_46fed949-e65d-474a-95d6-1c8c311ca74c_2\", \"run_number\": 1668564490, \"metric\": 0.90815695, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2022-11-16T02:08:20.628025Z\", \"end_time\": \"2022-11-16T02:08:35.170159Z\", \"created_time\": \"2022-11-16T02:08:10.839822Z\", \"created_time_dt\": \"2022-11-16T02:08:10.839822Z\", \"duration\": \"0:00:24\", \"hyperdrive_id\": \"46fed949-e65d-474a-95d6-1c8c311ca74c\", \"arguments\": null, \"param_--C\": 0.1, \"param_--max_iter\": 50, \"best_metric\": 0.90815695}, {\"run_id\": \"HD_46fed949-e65d-474a-95d6-1c8c311ca74c_3\", \"run_number\": 1668564491, \"metric\": 0.8532287, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2022-11-16T02:08:20.474499Z\", \"end_time\": \"2022-11-16T02:08:34.462933Z\", \"created_time\": \"2022-11-16T02:08:11.024116Z\", \"created_time_dt\": \"2022-11-16T02:08:11.024116Z\", \"duration\": \"0:00:23\", \"hyperdrive_id\": \"46fed949-e65d-474a-95d6-1c8c311ca74c\", \"arguments\": null, \"param_--C\": 0.01, \"param_--max_iter\": 10, \"best_metric\": 0.90815695}], \"children_metrics\": {\"categories\": [0], \"series\": {\"AUC_weighted\": [{\"categories\": [1668564490, 1668564491], \"mode\": \"markers\", \"name\": \"AUC_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.908156946501774, 0.8532287023321508]}, {\"categories\": [1668564490, 1668564491], \"mode\": \"lines\", \"name\": \"AUC_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.908156946501774, 0.908156946501774]}]}, \"metricName\": null, \"primaryMetricName\": \"AUC_weighted\", \"showLegend\": false}, \"run_metrics\": [{\"name\": \"best_child_by_primary_metric\", \"run_id\": \"HD_46fed949-e65d-474a-95d6-1c8c311ca74c\", \"categories\": [0], \"series\": [{\"data\": [{\"time_elapse\": [61, 151], \"metric_value\": [0.9229796410486066, 0.9229796410486066], \"metric_name\": [\"AUC_weighted\", \"AUC_weighted\"], \"run_id\": [\"HD_46fed949-e65d-474a-95d6-1c8c311ca74c_1\", \"HD_46fed949-e65d-474a-95d6-1c8c311ca74c_1\"], \"final\": [false, true]}]}]}], \"run_logs\": \"[2022-11-16T02:08:09.579217][GENERATOR][INFO]Trying to sample '5' jobs from the hyperparameter space\\n[2022-11-16T02:08:10.3151229Z][SCHEDULER][INFO]Scheduling job, id='HD_46fed949-e65d-474a-95d6-1c8c311ca74c_0' \\n[2022-11-16T02:08:10.4484425Z][SCHEDULER][INFO]Scheduling job, id='HD_46fed949-e65d-474a-95d6-1c8c311ca74c_1' \\n[2022-11-16T02:08:10.5330457Z][SCHEDULER][INFO]Scheduling job, id='HD_46fed949-e65d-474a-95d6-1c8c311ca74c_2' \\n[2022-11-16T02:08:10.5912449Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_46fed949-e65d-474a-95d6-1c8c311ca74c_0' \\n[2022-11-16T02:08:10.6901120Z][SCHEDULER][INFO]Scheduling job, id='HD_46fed949-e65d-474a-95d6-1c8c311ca74c_3' \\n[2022-11-16T02:08:10.7219207Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_46fed949-e65d-474a-95d6-1c8c311ca74c_1' \\n[2022-11-16T02:08:10.762684][GENERATOR][INFO]Successfully sampled '5' jobs, they will soon be submitted to the execution target.\\n[2022-11-16T02:08:10.8146859Z][SCHEDULER][INFO]Scheduling job, id='HD_46fed949-e65d-474a-95d6-1c8c311ca74c_4' \\n[2022-11-16T02:08:10.9392797Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_46fed949-e65d-474a-95d6-1c8c311ca74c_2' \\n[2022-11-16T02:08:11.0268483Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_46fed949-e65d-474a-95d6-1c8c311ca74c_4' \\n[2022-11-16T02:08:11.1100121Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_46fed949-e65d-474a-95d6-1c8c311ca74c_3' \\n[2022-11-16T02:09:10.186424][GENERATOR][INFO]Max number of jobs '5' reached for experiment.\\n[2022-11-16T02:09:10.283959][GENERATOR][INFO]All jobs generated.\\n[2022-11-16T02:10:42.329579][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FINISHED'.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.44.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the hyperdrive experiments and display all the properties of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "gather": {
     "logged": 1668564749065
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AUC_weighted': 0.9229796410486066}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "gather": {
     "logged": 1668570262809
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'runId': 'HD_46fed949-e65d-474a-95d6-1c8c311ca74c_1', 'target': 'nba-compute', 'status': 'Completed', 'startTimeUtc': '2022-11-16T02:08:20.881909Z', 'endTimeUtc': '2022-11-16T02:08:34.960905Z', 'services': {}, 'properties': {'_azureml.ComputeTargetType': 'amlctrain', 'ContentSnapshotId': 'ef8ee8bf-5846-4567-91ea-3153225be85f', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'train.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--data_directory', './data', '--C', '0.1', '--max_iter', '100'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'nba-compute', 'dataReferences': {}, 'data': {}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': 2592000, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'sklearn_env', 'version': 'Autosave_2022-11-16T00:40:57Z_bc5186cb', 'assetId': 'azureml://locations/southcentralus/workspaces/260111fa-1d62-47e0-8a2c-7c2f5739d572/environments/sklearn_env/versions/Autosave_2022-11-16T00:40:57Z_bc5186cb', 'autoRebuild': True, 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.2', 'scikit-learn', 'numpy', 'pandas', {'pip': ['azureml-defaults']}]}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': None}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'user_logs/std_log.txt': 'https://mlstrg215640.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_46fed949-e65d-474a-95d6-1c8c311ca74c_1/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=C72qMjeN9GaFDKBFfXkKHjdQ73K5n%2BuinJtOgA3UYhA%3D&skoid=843a364e-dd11-4f0c-b65f-a5c5aca461d0&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2022-11-16T00%3A30%3A58Z&ske=2022-11-17T08%3A40%3A58Z&sks=b&skv=2019-07-07&st=2022-11-16T03%3A34%3A22Z&se=2022-11-16T11%3A44%3A22Z&sp=r', 'system_logs/cs_capability/cs-capability.log': 'https://mlstrg215640.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_46fed949-e65d-474a-95d6-1c8c311ca74c_1/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=gLxiOKIcWSsw0TRqH69ikg9Na1fKniGSED5IQyO952g%3D&skoid=843a364e-dd11-4f0c-b65f-a5c5aca461d0&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2022-11-16T00%3A30%3A58Z&ske=2022-11-17T08%3A40%3A58Z&sks=b&skv=2019-07-07&st=2022-11-16T03%3A34%3A22Z&se=2022-11-16T11%3A44%3A22Z&sp=r', 'system_logs/hosttools_capability/hosttools-capability.log': 'https://mlstrg215640.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_46fed949-e65d-474a-95d6-1c8c311ca74c_1/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=80mVtsLg6dIC6W7aac50qwY77mfCXv9%2FhA1QLwAYtO0%3D&skoid=843a364e-dd11-4f0c-b65f-a5c5aca461d0&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2022-11-16T00%3A30%3A58Z&ske=2022-11-17T08%3A40%3A58Z&sks=b&skv=2019-07-07&st=2022-11-16T03%3A34%3A22Z&se=2022-11-16T11%3A44%3A22Z&sp=r', 'system_logs/lifecycler/execution-wrapper.log': 'https://mlstrg215640.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_46fed949-e65d-474a-95d6-1c8c311ca74c_1/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=ertTLw%2BFPLLrZuYgI0bA99MfFVc8MbvIs7mNHo7250o%3D&skoid=843a364e-dd11-4f0c-b65f-a5c5aca461d0&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2022-11-16T00%3A30%3A58Z&ske=2022-11-17T08%3A40%3A58Z&sks=b&skv=2019-07-07&st=2022-11-16T03%3A34%3A22Z&se=2022-11-16T11%3A44%3A22Z&sp=r', 'system_logs/lifecycler/lifecycler.log': 'https://mlstrg215640.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_46fed949-e65d-474a-95d6-1c8c311ca74c_1/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=3RRpeltpxg31GeAxah87MLaOlGQGCTvyR6LkXuObnCg%3D&skoid=843a364e-dd11-4f0c-b65f-a5c5aca461d0&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2022-11-16T00%3A30%3A58Z&ske=2022-11-17T08%3A40%3A58Z&sks=b&skv=2019-07-07&st=2022-11-16T03%3A34%3A22Z&se=2022-11-16T11%3A44%3A22Z&sp=r', 'system_logs/metrics_capability/metrics-capability.log': 'https://mlstrg215640.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_46fed949-e65d-474a-95d6-1c8c311ca74c_1/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=AS65QR3nV5Fsv9dtTG0U4qo2pqep1T3S2%2Fb9wo2d5gk%3D&skoid=843a364e-dd11-4f0c-b65f-a5c5aca461d0&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2022-11-16T00%3A30%3A58Z&ske=2022-11-17T08%3A40%3A58Z&sks=b&skv=2019-07-07&st=2022-11-16T03%3A34%3A22Z&se=2022-11-16T11%3A44%3A22Z&sp=r', 'system_logs/snapshot_capability/snapshot-capability.log': 'https://mlstrg215640.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_46fed949-e65d-474a-95d6-1c8c311ca74c_1/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=qg5K3pUILflDfvb%2BJuWTJryKViTMhLLIdpsu1inNpas%3D&skoid=843a364e-dd11-4f0c-b65f-a5c5aca461d0&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2022-11-16T00%3A30%3A58Z&ske=2022-11-17T08%3A40%3A58Z&sks=b&skv=2019-07-07&st=2022-11-16T03%3A34%3A22Z&se=2022-11-16T11%3A44%3A22Z&sp=r'}, 'submittedBy': 'ODL_User 215640'}\n"
     ]
    }
   ],
   "source": [
    "print(best_run.get_details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "gather": {
     "logged": 1668564752149
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/model.joblib',\n",
       " 'system_logs/cs_capability/cs-capability.log',\n",
       " 'system_logs/hosttools_capability/hosttools-capability.log',\n",
       " 'system_logs/lifecycler/execution-wrapper.log',\n",
       " 'system_logs/lifecycler/lifecycler.log',\n",
       " 'system_logs/metrics_capability/metrics-capability.log',\n",
       " 'system_logs/snapshot_capability/snapshot-capability.log',\n",
       " 'user_logs/std_log.txt']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run.get_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "gather": {
     "logged": 1668564755307
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "best_model = best_run.register_model(\n",
    "    model_name='nba-hyperdrive', \n",
    "    model_path='outputs/model.joblib',\n",
    "    tags={\"version\":\"1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "gather": {
     "logged": 1668564758516
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "best_model = best_run.register_model(\n",
    "    model_name='nba-hyperdrive', \n",
    "    model_path='outputs/model.joblib',\n",
    "    tags={\"version\":\"1\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "gather": {
     "logged": 1668564760194
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nba-hyperdrive 2\n"
     ]
    }
   ],
   "source": [
    "print(best_model.name, best_model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained but you still need to register both the models. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "gather": {
     "logged": 1668564762843
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"assetId\": \"azureml://locations/southcentralus/workspaces/260111fa-1d62-47e0-8a2c-7c2f5739d572/environments/sklearn_env/versions/1\",\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"buildContext\": null,\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"sklearn_env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                \"scikit-learn\",\n",
       "                \"numpy\",\n",
       "                \"pandas\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults\"\n",
       "                    ]\n",
       "                }\n",
       "            ]\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"1\"\n",
       "}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_env.register(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "gather": {
     "logged": 1668564767340
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "hyperparameter_inf_config = InferenceConfig(\n",
    "    environment=ws.environments['sklearn_env'],\n",
    "    source_directory='.',\n",
    "    entry_script='hyperparameter_deploy.py'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "gather": {
     "logged": 1668564769579
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=2, memory_gb=4, enable_app_insights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "gather": {
     "logged": 1668564989775
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-11-16 02:13:01+00:00 Creating Container Registry if not exists.\n",
      "2022-11-16 02:13:01+00:00 Registering the environment.\n",
      "2022-11-16 02:13:02+00:00 Use the existing image.\n",
      "2022-11-16 02:13:02+00:00 Generating deployment configuration.\n",
      "2022-11-16 02:13:03+00:00 Submitting deployment to compute.\n",
      "2022-11-16 02:13:07+00:00 Checking the status of deployment hyperdrive-service..\n",
      "2022-11-16 02:16:01+00:00 Checking the status of inference endpoint hyperdrive-service.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "service = Model.deploy(\n",
    "    ws, \n",
    "    \"hyperdrive-service\",\n",
    "    [best_model],\n",
    "    hyperparameter_inf_config,\n",
    "    deployment_config\n",
    ")\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "gather": {
     "logged": 1668568268790
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "sample_data = x_test[:10].to_json()\n",
    "headers = {'Content_Type': 'application/json'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "gather": {
     "logged": 1668568269860
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "uri = service.scoring_uri\n",
    "resp = requests.post(uri, sample_data, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "gather": {
     "logged": 1668568271622
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "gather": {
     "logged": 1668568310522
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"result\": [1, 1, 1, 1, 1, 0, 0, 1, 1, 0]}'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "gather": {
     "logged": 1668568224802
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-11-16T03:08:14,075974862+00:00 - iot-server/run \\n2022-11-16T03:08:14,075953062+00:00 - rsyslog/run \\n2022-11-16T03:08:14,083981762+00:00 - gunicorn/run \\n2022-11-16T03:08:14,087323062+00:00 | gunicorn/run | \\n2022-11-16T03:08:14,095125362+00:00 | gunicorn/run | ###############################################\\n2022-11-16T03:08:14,101457362+00:00 | gunicorn/run | AzureML Container Runtime Information\\n2022-11-16T03:08:14,107857362+00:00 | gunicorn/run | ###############################################\\n2022-11-16T03:08:14,116730262+00:00 | gunicorn/run | \\n2022-11-16T03:08:14,120189062+00:00 | gunicorn/run | \\n2022-11-16T03:08:14,138381962+00:00 - nginx/run \\n2022-11-16T03:08:14,140696062+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20220708.v2\\n2022-11-16T03:08:14,150702762+00:00 | gunicorn/run | \\n2022-11-16T03:08:14,153845462+00:00 | gunicorn/run | \\n2022-11-16T03:08:14,160389362+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml_7eec2c8971b9410f92147a7e257297e7/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\\n2022-11-16T03:08:14,163464462+00:00 | gunicorn/run | PYTHONPATH environment variable: \\n2022-11-16T03:08:14,167521462+00:00 | gunicorn/run | \\n2022-11-16T03:08:14,177191662+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\\n\\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n2022-11-16T03:08:15,680668087+00:00 - iot-server/finish 1 0\\n2022-11-16T03:08:15,683487549+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nadal==1.2.7\\nargcomplete==2.0.0\\nattrs==22.1.0\\nazure-common==1.1.28\\nazure-core==1.24.2\\nazure-graphrbac==0.61.1\\nazure-identity==1.7.0\\nazure-mgmt-authorization==2.0.0\\nazure-mgmt-containerregistry==10.0.0\\nazure-mgmt-core==1.3.2\\nazure-mgmt-keyvault==10.0.0\\nazure-mgmt-resource==21.1.0\\nazure-mgmt-storage==20.0.0\\nazureml-core==1.47.0\\nazureml-dataprep==4.5.7\\nazureml-dataprep-native==38.0.0\\nazureml-dataprep-rslex==2.11.4\\nazureml-dataset-runtime==1.47.0\\nazureml-defaults==1.47.0\\nazureml-inference-server-http==0.7.7\\nbackports.tempfile==1.0\\nbackports.weakref==1.0.post1\\nbcrypt==4.0.1\\ncachetools==4.2.4\\ncertifi==2021.5.30\\ncffi==1.15.1\\ncharset-normalizer==2.0.12\\nclick==8.0.4\\ncloudpickle==2.2.0\\nconfigparser==3.7.4\\ncontextlib2==21.6.0\\ncontextvars==2.4\\ncryptography==38.0.3\\ndataclasses==0.8\\ndistro==1.8.0\\ndocker==5.0.3\\ndotnetcore2==3.1.23\\nFlask==2.0.3\\nFlask-Cors==3.0.10\\nfusepy==3.0.1\\ngoogle-api-core==2.8.2\\ngoogle-auth==2.14.1\\ngoogleapis-common-protos==1.56.3\\ngunicorn==20.1.0\\nhumanfriendly==10.0\\nidna==3.4\\nimmutables==0.19\\nimportlib-metadata==4.8.3\\ninference-schema==1.4.2.1\\nisodate==0.6.1\\nitsdangerous==2.0.1\\njeepney==0.7.1\\nJinja2==3.0.3\\njmespath==0.10.0\\njoblib @ file:///tmp/build/80754af9/joblib_1613502643832/work\\njson-logging-py==0.2\\njsonpickle==2.2.0\\njsonschema==3.2.0\\nknack==0.10.0\\nMarkupSafe==2.0.1\\nmkl-fft==1.3.0\\nmkl-random==1.1.1\\nmkl-service==2.3.0\\nmsal==1.20.0\\nmsal-extensions==0.3.1\\nmsrest==0.7.1\\nmsrestazure==0.6.4\\nndg-httpsclient==0.5.1\\nnumpy @ file:///tmp/build/80754af9/numpy_and_numpy_base_1603487797006/work\\noauthlib==3.2.2\\nopencensus==0.11.0\\nopencensus-context==0.1.3\\nopencensus-ext-azure==1.1.7\\npackaging==21.3\\npandas==1.1.5\\nparamiko==2.12.0\\npathspec==0.9.0\\npkginfo==1.8.3\\nportalocker==2.6.0\\nprotobuf==3.19.6\\npsutil==5.9.4\\npyarrow==6.0.1\\npyasn1==0.4.8\\npyasn1-modules==0.2.8\\npycparser==2.21\\nPygments==2.13.0\\nPyJWT==2.4.0\\nPyNaCl==1.5.0\\npyOpenSSL==22.1.0\\npyparsing==3.0.7\\npyrsistent==0.18.0\\nPySocks==1.7.1\\npython-dateutil @ file:///tmp/build/80754af9/python-dateutil_1626374649649/work\\npytz==2021.3\\nPyYAML==6.0\\nrequests==2.27.1\\nrequests-oauthlib==1.3.1\\nrsa==4.9\\nscikit-learn @ file:///tmp/build/80754af9/scikit-learn_1621365798935/work\\nscipy @ file:///tmp/build/80754af9/scipy_1597686625380/work\\nSecretStorage==3.3.3\\nsix @ file:///tmp/build/80754af9/six_1644875935023/work\\ntabulate==0.8.10\\nthreadpoolctl @ file:///Users/ktietz/demo/mc3/conda-bld/threadpoolctl_1629802263681/work\\ntyping_extensions==4.1.1\\nurllib3==1.26.12\\nwebsocket-client==1.3.1\\nWerkzeug==2.0.3\\nwrapt==1.12.1\\nzipp==3.6.0\\n\\n2022-11-16T03:08:18,440724768+00:00 | gunicorn/run | \\n2022-11-16T03:08:18,444301447+00:00 | gunicorn/run | ###############################################\\n2022-11-16T03:08:18,447281213+00:00 | gunicorn/run | AzureML Inference Server\\n2022-11-16T03:08:18,452430427+00:00 | gunicorn/run | ###############################################\\n2022-11-16T03:08:18,456920626+00:00 | gunicorn/run | \\n2022-11-16T03:08:20,224209273+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\\nValid Application Insights instrumentation key provided.\\n\\nAzure ML Inferencing HTTP server v0.7.7\\n\\n\\nServer Settings\\n---------------\\nEntry Script Name: /var/azureml-app/odl_user_215640/hyperparameter_deploy.py\\nModel Directory: /var/azureml-app/azureml-models/nba-hyperdrive/2\\nWorker Count: 1\\nWorker Timeout (seconds): 300\\nServer Port: 31311\\nApplication Insights Enabled: true\\nApplication Insights Key: AppInsights key provided\\nInferencing HTTP server version: azmlinfsrv/0.7.7\\nCORS for the specified origins: None\\n\\n\\nServer Routes\\n---------------\\nLiveness Probe: GET   127.0.0.1:31311/\\nScore:          POST  127.0.0.1:31311/score\\n\\nStarting gunicorn 20.1.0\\nListening at: http://0.0.0.0:31311 (85)\\nUsing worker: sync\\nBooting worker with pid: 140\\nInitializing logger\\n2022-11-16 03:08:23,103 | root | INFO | Starting up app insights client\\nDeprecationWarning: Explicitly using instrumentation key isdeprecated. Please use a connection string instead.\\nDeprecationWarning: Explicitly using instrumentation key isdeprecated. Please use a connection string instead.\\nDeprecationWarning: Explicitly using instrumentation key isdeprecated. Please use a connection string instead.\\nlogging socket was found. logging is available.\\nlogging socket was found. logging is available.\\n2022-11-16 03:08:28,370 | root | INFO | Starting up app insight hooks\\n2022-11-16 03:08:37,386 | root | INFO | Found user script at /var/azureml-app/odl_user_215640/hyperparameter_deploy.py\\n2022-11-16 03:08:37,386 | root | INFO | run() is not decorated. Server will invoke it with the input in JSON string.\\n2022-11-16 03:08:37,386 | root | INFO | Invoking user\\'s init function\\n/azureml-envs/azureml_7eec2c8971b9410f92147a7e257297e7/lib/python3.6/site-packages/azure/identity/_internal/aadclient_certificate.py:8: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.\\n  from cryptography import x509\\n2022-11-16 03:08:40,349 | root | INFO | Users\\'s init has completed successfully\\n00000000-0000-0000-0000-000000000000,/var/azureml-app/odl_user_215640/hyperparameter_deploy.py:4: FutureWarning: azureml.core: AzureML support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use AzureML will continue to work without modification, but Python 3.6 users will no longer get access to the latest AzureML features and bugfixes. We recommend that you upgrade to Python 3.7 or newer. To disable SDK V1 deprecation warning set the environment variable AZUREML_DEPRECATE_WARNING to \\'False\\'\\n  from azureml.core.model import Model\\n2022-11-16 03:08:40,355 | root | INFO | Swaggers are prepared for the following versions: [2, 3].\\n2022-11-16 03:08:40,356 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\\n2022-11-16 03:08:40,357 | root | INFO | AML_FLASK_ONE_COMPATIBILITY is set, but patching is not necessary.\\n2022-11-16 03:08:56,308 | root | INFO | 200\\n127.0.0.1 - - [16/Nov/2022:03:08:56 +0000] \"GET /swagger.json HTTP/1.0\" 200 2269 \"-\" \"Go-http-client/1.1\"\\n2022-11-16 03:09:00,289 | root | INFO | 200\\n127.0.0.1 - - [16/Nov/2022:03:09:00 +0000] \"GET /swagger.json HTTP/1.0\" 200 2269 \"-\" \"Go-http-client/1.1\"\\n2022-11-16 03:10:18,005 | root | INFO | 200\\n127.0.0.1 - - [16/Nov/2022:03:10:18 +0000] \"POST /score HTTP/1.0\" 200 19 \"-\" \"python-requests/2.28.1\"\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "gather": {
     "logged": 1668570372338
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
